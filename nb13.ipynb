{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NguG3E7fNQDC",
        "1z0tvvy1THBj",
        "oxHD9MO-sM_u",
        "QYxjEPjtVRDy",
        "77xY4Rv1VYDY",
        "kvdZDyqKvJXs",
        "eg42wHw3aBXL",
        "saboeG1-lT-X",
        "-FC9VX4zsnJa",
        "09KO0jduDIu-",
        "NHDbEEibA6uf",
        "yNmo207rflRW",
        "2uJ9oIQKf0fs",
        "Bxk5YLHMgXl_",
        "qld2ZK-hg4c6",
        "RN20gYTeg8lG"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwnbsiE2zGxa"
      },
      "source": [
        "*Теоретический материал:* https://youtu.be/TUx-Fe9BQoU?t=991"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NguG3E7fNQDC"
      },
      "source": [
        "# Подключение бибилиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hyWYiPqLdez"
      },
      "source": [
        "from tensorflow.keras.models import Model # Импортируем модели keras: Model\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization # Импортируем стандартные слои keras\n",
        "from tensorflow.keras import backend as K # Импортируем модуль backend keras'а\n",
        "from tensorflow.keras.optimizers import Adam # Импортируем оптимизатор Adam\n",
        "from tensorflow.keras import utils # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n",
        "from google.colab import files # Импортируем Модуль files для работы с файлами\n",
        "import matplotlib.pyplot as plt # Импортируем модуль pyplot библиотеки matplotlib для построения графиков\n",
        "from tensorflow.keras.preprocessing import image # Импортируем модуль image для работы с изображениями\n",
        "import numpy as np # Импортируем библиотеку numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import random\n",
        "import os # Импортируем библиотеку os для раоты с фаловой системой\n",
        "from PIL import Image # импортируем модель Image для работы с изображениями"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAQPho1XuauH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b17dd16-bb16-4c0c-af2b-fc8b51bf0295"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.2.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP4-NkAt96gv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5254ae30-71d3-4402-9520-fa967deb3235"
      },
      "source": [
        "from google.colab import drive # Подключаем гугл-диск\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z0tvvy1THBj"
      },
      "source": [
        "# Сегментация стройки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxHD9MO-sM_u"
      },
      "source": [
        "## Загрузка картинок\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=2140"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbNtynGfV27x"
      },
      "source": [
        "# Глобальные параметры\n",
        "img_width = 176 # Ширина уменьшенной картинки \n",
        "img_height = 240 # Высота уменьшенной картинки \n",
        "num_classes = 7 # Задаем количество классов на изображении\n",
        "directory = '/content/drive/My Drive/Базы/Тестовое_стажировка_сегментация/' # Указываем путь к обучающей выборке с оригинальными изображения\n",
        "train_directory = 'Тренировочная_стройка' # Название папки с файлами обучающей выборки\n",
        "val_directory = 'Проверочная_стройка' # Название папки с файлами проверочной выборки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYxjEPjtVRDy"
      },
      "source": [
        "### Оригинальные изображения\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=2258"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRDvv0-DQHwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "2556246b-3977-407f-8263-d07d56d74072"
      },
      "source": [
        "train_images = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n",
        "val_images = [] # Создаем пустой список для хранений оригинльных изображений проверочной выборки\n",
        "test_images = [] # Создаем пустой список для хранений оригинльных изображений тестовой выборки\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "for filename in sorted(os.listdir(directory + train_directory+'/Исходники')): # Проходим по всем файлам в каталоге по указанному пути     \n",
        "    train_images.append(image.load_img(os.path.join(directory + train_directory+'/Исходники',filename),\n",
        "                                       target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n",
        "print ('Обучающая выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок обучающей выборки\n",
        "print ('Количество изображений: ', len(train_images)) # Отображаем количество элементов в обучающей выборке\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "for filename in sorted(os.listdir(directory + val_directory+'/Исходники')): # Проходим по всем файлам в каталоге по указанному пути                  \n",
        "    val_images.append(image.load_img(os.path.join(directory + val_directory+'/Исходники',filename), \n",
        "                                     target_size=(img_width, img_height)))  # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size   \n",
        "print ('Проверочная выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок проверочной выборки\n",
        "print ('Количество изображений: ', len(val_images)) # Отображаем количество элементов в проверочной выборке"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cafd60d8ab06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcur_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Засекаем текущее время\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_directory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Исходники'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Проходим по всем файлам в каталоге по указанному пути\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     train_images.append(image.load_img(os.path.join(directory + train_directory+'/Исходники',filename),\n\u001b[1;32m      8\u001b[0m                                        target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Базы/Тестовое_стажировка_сегментация/Тренировочная_стройка/Исходники'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A0a9pZxQeQM"
      },
      "source": [
        "n = 5 # Количество выводимых случайных картинок\n",
        "fig, axs = plt.subplots(1, n, figsize=(25, 5)) #Создаем полотно из n графиков\n",
        "for i in range(n): # Выводим в цикле n случайных изображений\n",
        "  img = random.choice(train_images) # Выбираем случайное фото для отображения\n",
        "  axs[i].imshow(img) # Отображаем фото\n",
        "plt.show() #Показываем изображения"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77xY4Rv1VYDY"
      },
      "source": [
        "### Сегментированные изображения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyA-q3d5YOL5"
      },
      "source": [
        "train_segments = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n",
        "val_segments = [] # Создаем пустой список для хранений оригинльных изображений проверочной выборки\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "for filename in sorted(os.listdir(directory + train_directory+'/Размеченные')): # Проходим по всем файлам в каталоге по указанному пути     \n",
        "    train_segments.append(image.load_img(os.path.join(directory + train_directory+'/Размеченные',filename),\n",
        "                                       target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n",
        "print ('Обучающая выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок обучающей выборки\n",
        "print ('Количество изображений: ', len(train_segments)) # Отображаем количество элементов в обучающем наборе сегментированных изображений\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "# Проходим по всем файлам в каталоге по указанному пути \n",
        "for filename in sorted(os.listdir(directory + val_directory+'/Размеченные')):\n",
        "    # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n",
        "    val_segments.append(image.load_img(os.path.join(directory + val_directory+'/Размеченные',filename), \n",
        "                                     target_size=(img_width, img_height)))  # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size   \n",
        "print ('Проверочная выборка загржуена. Время загрузки: ', round(time.time() - cur_time, 2), 'c', sep='') # Отображаем время загрузки картинок проверочной выборки\n",
        "print ('Количество изображений: ', len(val_segments)) # Отображаем количество элементов в проверочном наборе сегментированных изображений"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTeP2kM9yIgH"
      },
      "source": [
        "n = 5 # Количество выводимых случайных картинок\n",
        "fig, axs = plt.subplots(1, n, figsize=(25, 5)) #Создаем полотно из n графиков\n",
        "for i in range(n): # Выводим в цикле n случайных изображений\n",
        "  img = random.choice(train_segments) # Выбираем случайное фото для отображения\n",
        "  axs[i].imshow(img) # Отображаем фото\n",
        "plt.show() #Показываем изображения"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvdZDyqKvJXs"
      },
      "source": [
        "## Создание выборки\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=2393"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbK0KhHFvebD"
      },
      "source": [
        "# Функция преобразования пикселя сегментированного изображения в индекс (7 классов)\n",
        "def color2index(color):\n",
        "  index=-1\n",
        "  if (149>=color[0]>51)and(149>=color[1]>=51)and(149>=color[2]>=51) : index=0 # пол\n",
        "  elif (49>=color[0]>=0)and(49>=color[1]>=0)and(149>=color[2]>=51) : index=1 # потолок\n",
        "  elif (49>=color[0]>=0)and(149>=color[1]>=51)and(49>=color[2]>=0) : index=2 # стена\n",
        "  elif (149>=color[0]>=51)and(49>=color[1]>=0)and(49>=color[2]>=0) : index=4 # колонна\n",
        "  elif (49>=color[0]>=0)and(149>=color[1]>=51)and(149>=color[2]>=51) : index=3 # проем\n",
        "  elif (149>=color[0]>=51)and(49>=color[1]>=0)and(149>=color[2]>=51) : index=3 # дверь\n",
        "  elif (149>=color[0]>=51)and(149>=color[1]>=51)and(49>=color[2]>=0) : index=3 # окно\n",
        "  elif (249>=color[0]>=151)and(249>=color[1]>=151)and(249>=color[2]>=151) : index=4 # внешний мир\n",
        "  elif (49>=color[0]>=0)and(49>=color[1]>=51)and(249>=color[2]>=151) : index=4 # лестница\n",
        "  elif (49>=color[0]>=0)and(249>=color[1]>=151)and(49>=color[2]>=0) : index=4 # перила\n",
        "  elif (249>=color[0]>=151)and(49>=color[1]>=0)and(49>=color[2]>=0) : index=4 # батарея\n",
        "  elif (49>=color[0]>=0)and(249>=color[1]>=151)and(249>=color[2]>=151) : index=5 # люди\n",
        "  elif (249>=color[0]>=151)and(49>=color[1]>=0)and(249>=color[2]>=151) : index=4 # инвентарь\n",
        "  elif (249>=color[0]>=151)and(249>=color[1]>=151)and(49>=color[2]>=0) : index=4 # источники света\n",
        "  elif (49>=color[0]>=0)and(149>=color[1]>=51)and(249>=color[2]>=151) : index=4 # провода\n",
        "  elif (149>=color[0]>=51)and(49>=color[1]>=0)and(249>=color[2]>=151) : index=4 # балка\n",
        "  else: index=6\n",
        "  return index  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6rcETLr9PpT"
      },
      "source": [
        "# Функция преобразования индекса в цвет пикселя\n",
        "def index2color(index2):\n",
        "  index = np.argmax(index2) # Получаем индекс максимального элемента\n",
        "  color=[]\n",
        "  if index == 0: color = [100, 100, 100]  # пол\n",
        "  elif index == 1: color = [0, 0, 100]  # потолок\n",
        "  elif index == 2: color = [0, 100, 0]  # стена\n",
        "  elif index == 3: color = [100, 0, 0]  # проем, дверь, окно\n",
        "  elif index == 4: color = [0, 100, 100]  # колонна, лестница, внешний мир, перила, батарея, инвентарь, источники света, провода, балка\n",
        "  elif index == 5: color = [100, 0, 100]  # люди\n",
        "  elif index == 6: color = [0, 0, 0]  # остальное\n",
        "  return color # Возвращаем цвет пикслея"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE1uCwYPxiix"
      },
      "source": [
        "# Функция перевода индекса пикслея в to_categorical\n",
        "def rgbToohe(y, num_classes): \n",
        "  y2 = y.copy() # Создаем копию входного массива\n",
        "  y = y.reshape(y.shape[0] * y.shape[1], 3) # Решейпим в двумерный массив\n",
        "  yt = [] # Создаем пустой лист\n",
        "  for i in range(len(y)): # Проходим по всем трем канала изображения\n",
        "    yt.append(utils.to_categorical(color2index(y[i]), num_classes=num_classes)) # Переводим пиксели в индексы и преобразуем в OHE\n",
        "  yt = np.array(yt) # Преобразуем в numpy\n",
        "  yt = yt.reshape(y2.shape[0], y2.shape[1], num_classes) # Решейпим к исходныму размеру\n",
        "  return yt # Возвращаем сформированный массив"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOZdr1l9w3-5"
      },
      "source": [
        "# Функция формирования yTrain\n",
        "def yt_prep(data, num_classes):\n",
        "  yTrain = [] # Создаем пустой список под карты сегметации\n",
        "  for seg in data: # Пробегаем по всем файлам набора с сегминтированными изображениями\n",
        "    y = image.img_to_array(seg) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "    y = rgbToohe(y, num_classes) # Получаем OHE-представление сформированного массива\n",
        "    yTrain.append(y) # Добавляем очередной элемент в yTrain\n",
        "    if len(yTrain) % 100 == 0: # Каждые 100 шагов\n",
        "      print(len(yTrain)) # Выводим количество обработанных изображений\n",
        "  return np.array(yTrain) # Возвращаем сформированный yTrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtJ1tricv9uO"
      },
      "source": [
        "xTrain = [] # Создаем пустой список под обучающую выборку\n",
        "for img in train_images: # Проходим по всем изображениям из train_images\n",
        "  x = image.img_to_array(img) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "  xTrain.append(x) # Добавляем очередной элемент в xTrain\n",
        "xTrain = np.array(xTrain) # Переводим в numpy\n",
        "\n",
        "xVal = [] # Создаем пустой список под проверочную выборку\n",
        "for img in val_images: # Проходим по всем изображениям из val_images\n",
        "  x = image.img_to_array(img) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "  xVal.append(x) # Добавляем очередной элемент в xTrain\n",
        "xVal = np.array(xVal) # Переводим в numpy\n",
        "\n",
        "print(xTrain.shape) # Размерность обучающей выборки\n",
        "print(xVal.shape) # Размерность проверочной выборки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X6ro3njwh-H"
      },
      "source": [
        "cur_time = time.time() # Засекаем текущее время\n",
        "yTrain = yt_prep(train_segments, num_classes)  # Создаем yTrain\n",
        "print('Время обработки: ', round(time.time() - cur_time, 2),'c') # Выводим время работы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6XPko4NyJrm"
      },
      "source": [
        "cur_time = time.time() # Засекаем текущее время\n",
        "yVal = yt_prep(val_segments, num_classes) # Создаем yVal\n",
        "print('Время обработки: ', round(time.time() - cur_time, 2),'c') # Выводим время работы"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkzing6o49Sn"
      },
      "source": [
        "yTrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg42wHw3aBXL"
      },
      "source": [
        "## Модели\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=3055"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVDD6PnZaMnq"
      },
      "source": [
        "# Функция визуализации сегментированных изображений\n",
        "def processImage(model, count = 1, n_classes = 6):\n",
        "  indexes = np.random.randint(0, len(xVal), count) # Получаем count случайных индексов\n",
        "  fig, axs = plt.subplots(3, count, figsize=(25, 5)) #Создаем полотно из n графиков\n",
        "  for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\n",
        "    predict = np.array(model.predict(xVal[idx].reshape(1, img_width, img_height, 3))) # Предиктим картику\n",
        "    pr = predict[0] # Берем нулевой элемент из перидкта\n",
        "    pr1 = [] # Пустой лист под сегментированную картинку из predicta\n",
        "    pr2 = [] # Пустой лист под сегменитрованную картинку из yVal\n",
        "    pr = pr.reshape(-1, n_classes) # Решейпим предикт\n",
        "    yr = yVal[idx].reshape(-1, n_classes) # Решейпим yVal\n",
        "    for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\n",
        "      pr1.append(index2color(pr[k])) # Переводим индекс в писксель\n",
        "      pr2.append(index2color(yr[k])) # Переводим индекс в писксель\n",
        "    pr1 = np.array(pr1) # Преобразуем в numpy\n",
        "    pr1 = pr1.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n",
        "    pr2 = np.array(pr2) # Преобразуем в numpy\n",
        "    pr2 = pr2.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n",
        "    img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\n",
        "    axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\n",
        "    axs[1,i].imshow(Image.fromarray(pr2.astype('uint8'))) # Отображаем на графике во второй линии сегментированное изображение из yVal\n",
        "    axs[2,i].imshow(Image.fromarray(xVal[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \n",
        "  plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saboeG1-lT-X"
      },
      "source": [
        "### Линейная сегментирующая сеть\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=3426"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz9NJZsW6Eua"
      },
      "source": [
        "'''\n",
        "  Собственная функция метрики, обрабатывающая пересечение двух областей\n",
        "'''\n",
        "def dice_coef(y_true, y_pred):\n",
        "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.) # Возвращаем площадь пересечения деленную на площадь объединения двух областей"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJEhXlIDlTgN"
      },
      "source": [
        "'''\n",
        "  Функция создания сети\n",
        "    Входные параметры:\n",
        "    - num_classes - количество классов\n",
        "    - input_shape - размерность карты сегментации\n",
        "'''\n",
        "def linearSegmentationNet(\n",
        "      num_classes = 6,\n",
        "      input_shape = (176, 240, 3)\n",
        "      ):\n",
        "    img_input = Input(input_shape)                                          # Создаем входной слой с размерностью input_shape\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                             # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                               # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                             # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                               # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes,(3, 3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x)                                             # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель\n",
        "    model.compile(optimizer=Adam(lr=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    return model # Возвращаем сформированную модель"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDQZK3xdjxo5"
      },
      "source": [
        "modelL = linearSegmentationNet(num_classes, (img_width, img_height, 3)) # Создаем моель linearSegmentationNet\n",
        "modelL.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7AQ2g-yljo-"
      },
      "source": [
        "modelL = linearSegmentationNet(num_classes, (img_width, img_height, 3)) # Создаем моель linearSegmentationNet\n",
        "history = modelL.fit(xTrain, yTrain, epochs=10, batch_size=32, validation_data=(xVal, yVal)) # Обучаем модель на выборке по трем классам"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gswffbh8AmEo"
      },
      "source": [
        "# Отобразим график обучения модели\n",
        "plt.plot(history.history['dice_coef'])\n",
        "plt.plot(history.history['val_dice_coef'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Di3O-r-oEL9"
      },
      "source": [
        "#modelL.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelL.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YulllVQg9Dl0"
      },
      "source": [
        "#### Распознавание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Nb0oVpppeG"
      },
      "source": [
        "modelL = linearSegmentationNet(num_classes, (img_width, img_height, 3)) # Создаем моель linearSegmentationNet\n",
        "modelL.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelL.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N01FiT5jkBnd"
      },
      "source": [
        "processImage(modelL, 5, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FC9VX4zsnJa"
      },
      "source": [
        "### U-net\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=4438"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-n-ivxFLKOF"
      },
      "source": [
        "'''\n",
        "  Функция создания сети\n",
        "    Входные параметры:\n",
        "    - num_classes - количество классов\n",
        "    - input_shape - размерность карты сегментации\n",
        "'''\n",
        "def unet(num_classes = 3, input_shape= (88, 120, 3)):\n",
        "    img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)        # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)        # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n",
        "\n",
        "    x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_3_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_3_out\n",
        "\n",
        "    x = MaxPooling2D()(block_3_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)        # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_4_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_4_out\n",
        "    x = block_4_out \n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_3_out])                                      # Объединем текущий слой со слоем block_3_out\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    # UP 3\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_2_out])                                      # Объединем текущий слой со слоем block_2_out\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_1_out])  # Объединем текущий слой со слоем block_1_out\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель \n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    \n",
        "    return model # Возвращаем сформированную модель"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFlktpNPRtVC"
      },
      "source": [
        "modelUnet = unet(num_classes, (img_width, img_height, 3)) # Создаем модель unet\n",
        "history = modelUnet.fit(xTrain, yTrain, epochs=30, batch_size=32, validation_data = (xVal, yVal)) # Обучаем модель на выборке по трем классам"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAFRc5E32QAn"
      },
      "source": [
        "#modelUnet.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelUnet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaAiNqnDsxgf"
      },
      "source": [
        "#### Распознавание\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=5163"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TaPLDbQplA8"
      },
      "source": [
        "modelUnet = unet(num_classes, (img_width, img_height, 3)) # Создаем модель unet\n",
        "modelUnet.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelUnet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPWVBHNLhHir"
      },
      "source": [
        "processImage(modelUnet, 5, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09KO0jduDIu-"
      },
      "source": [
        "### Упрощённая U-net\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=5235"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSLJRhASDOxJ"
      },
      "source": [
        "'''\n",
        "  Функция создания сети\n",
        "    Входные параметры:\n",
        "    - num_classes - количество классов\n",
        "    - input_shape - размерность карты сегментации\n",
        "'''\n",
        "def simpleUnet(num_classes = 6, input_shape= (352, 480, 3)):\n",
        "    img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(32, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 32-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 32-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block2_conv1')(x)         # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block2_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n",
        "\n",
        "    x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n",
        "    \n",
        "    # UP 1\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)     # Добавляем Conv2DTranspose-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(x)     # Добавляем Conv2DTranspose-слой с 32-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 32-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding='same')(x)                              # Добавляем Conv2D-слой с 32-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes,(3,3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x)                                            # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель\n",
        "    model.compile(optimizer=Adam(lr=1e-3),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    \n",
        "    return model                                                           # Возвращаем модель"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w18aR1NJDoW6"
      },
      "source": [
        "modelS = simpleUnet(num_classes, (img_width, img_height, 3))                                                              # Создаем модель simpleUnet\n",
        "history = modelS.fit(xTrain, yTrain, epochs=30, batch_size=32, validation_data = (xVal, yVal)) # Обучаем модель на выборке по трем классам"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spyguz1voovb"
      },
      "source": [
        "#modelS.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelS.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djINNTLqnymg"
      },
      "source": [
        "#### Распознавание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_d3FCctpdpN"
      },
      "source": [
        "modelS = simpleUnet(num_classes, (img_width, img_height, 3))    \n",
        "modelS.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelS.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIQyKGUHD2tG"
      },
      "source": [
        "processImage(modelS, 5, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHDbEEibA6uf"
      },
      "source": [
        "### Расширенная U-net\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=5340"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOjFjIERBFId"
      },
      "source": [
        "'''\n",
        "  Функция создания сети\n",
        "    Входные параметры:\n",
        "    - num_classes - количество классов\n",
        "    - input_shape - размерность карты сегментации\n",
        "'''\n",
        "def unetWithMask(num_classes = 6, input_shape= (352, 480, 3)):\n",
        "    img_input = Input(input_shape)                                      # Создаем входной слой с размерностью input_shape\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)      # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    block_1_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_1_out\n",
        "    \n",
        "    block_1_out_mask = Conv2D(64, (1, 1), padding='same')(block_1_out)  # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_1_out_mask\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out) # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)     # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)     # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    block_2_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_2_out\n",
        "\n",
        "    block_2_out_mask = Conv2D(128, (1, 1), padding='same')(block_2_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_2_out_mask\n",
        "    \n",
        "    x = MaxPooling2D()(block_2_out)                                     # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)     # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    block_3_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_3_out\n",
        "\n",
        "    block_3_out_mask = Conv2D(256, (1, 1), padding='same')(block_3_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_3_out_mask\n",
        "        \n",
        "    x = MaxPooling2D()(block_3_out)                                     # Добавляем слой MaxPooling2D\n",
        "\n",
        "     # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)     # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)     # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    block_4_out = Activation('relu')(x)                                 # Добавляем слой Activation и запоминаем в переменной block_4_out\n",
        "\n",
        "    block_4_out_mask = Conv2D(512, (1, 1), padding='same')(block_4_out) # Добавляем Conv2D-маску к текущему слою и запоминаем в переменную block_4_out_mask\n",
        "            \n",
        "    x = MaxPooling2D()(block_4_out)                                     # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)     # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)     # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)     # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "    \n",
        "    for_pretrained_weight = MaxPooling2D()(x)                           # Добавляем слой MaxPooling2D\n",
        " \n",
        "    # UP 1\n",
        "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 512 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_4_out, block_4_out_mask])                 # Объединем текущий слой со слоем block_4_out и слоем-маской block_4_out_mask\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 512 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_3_out, block_3_out_mask])                 # Объединем текущий слой со слоем block_3_out и слоем-маской block_3_out_mask\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    # UP 3\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_2_out, block_2_out_mask])                 # Объединем текущий слой со слоем block_2_out и слоем-маской block_2_out_mask\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                         # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                           # Добавляем слой Activation\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n",
        "    x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                          # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_1_out, block_1_out_mask])                # Объединем текущий слой со слоем block_1_out и слоем-маской block_1_out_mask\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                          # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)                          # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                        # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                          # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x) # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x)                                        # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель \n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    \n",
        "    return model                                                       # Возвращаем сформированную модель"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXHrGrKDBwPQ"
      },
      "source": [
        "modelM3 = unetWithMask(num_classes, (img_width, img_height,3))\n",
        "history = modelM3.fit(xTrain, yTrain, epochs=20, batch_size=16, validation_data = (xVal, yVal)) #  Обучаем модель на выборке по трем классам на полноразмерных изображениях"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L_vHc2UGro3"
      },
      "source": [
        "#modelM3.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelM3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0V_SvtOp__C"
      },
      "source": [
        "#### Распознавание\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=5518"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA5zxadGqFkK"
      },
      "source": [
        "modelM3 = unetWithMask(num_classes, (img_width, img_height,3))\n",
        "modelM3.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelM3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ5cAEsIqFEC"
      },
      "source": [
        "processImage(modelM3, 5, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNmo207rflRW"
      },
      "source": [
        "# Сегментация самолетов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66F4EJuffnRb"
      },
      "source": [
        "# Глобальные параметры\n",
        "img_width = 176 # Ширина уменьшенной картинки \n",
        "img_height =  320 # Высота уменьшенной картинки \n",
        "directory = '/content/drive/My Drive/Базы/Самолеты/' # Указываем путь к обучающей выборке с оригинальными изображения\n",
        "num_classes = 2 # Количество классов на изображении"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uJ9oIQKf0fs"
      },
      "source": [
        "## Загрузка изображений\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=6495"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-2N0mcEf2nT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8229b51c-0412-489a-9c52-dd496225388c"
      },
      "source": [
        "images_airplane = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "for filename in sorted(os.listdir(directory + 'Самолеты')): # Проходим по всем файлам в каталоге по указанному пути     \n",
        "    images_airplane.append(image.load_img(os.path.join(directory + 'Самолеты',filename),\n",
        "                                       target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n",
        "print ('Обучающая выборка загржуена. Время загрузки: ', time.time() - cur_time, 'c', sep='') # Отображаем время загрузки картинок обучающей выборки"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-14f31c47c4bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Самолеты'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Проходим по всем файлам в каталоге по указанному пути\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     images_airplane.append(image.load_img(os.path.join(directory + 'Самолеты',filename),\n\u001b[0;32m----> 6\u001b[0;31m                                        target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Обучающая выборка загржуена. Время загрузки: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcur_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Отображаем время загрузки картинок обучающей выборки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    299\u001b[0m   \"\"\"\n\u001b[1;32m    300\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 301\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-0-5dgEgF41"
      },
      "source": [
        "n = 5 # Количество выводимых случайных картинок\n",
        "fig, axs = plt.subplots(1, n, figsize=(25, 5)) #Создаем полотно из n графиков\n",
        "for i in range(n): # Выводим в цикле n случайных изображений\n",
        "  img = random.choice(images_airplane) # Выбираем случайное фото для отображения\n",
        "  axs[i].imshow(img) # Отображаем фото\n",
        "plt.show() #Показываем изображения"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KO-fJecgKi_"
      },
      "source": [
        "segments_airplane = [] # Создаем пустой список для хранений оригинльных изображений обучающей выборки\n",
        "\n",
        "cur_time = time.time() # Засекаем текущее время\n",
        "for filename in sorted(os.listdir(directory + 'Segment')): # Проходим по всем файлам в каталоге по указанному пути     \n",
        "    segments_airplane.append(image.load_img(os.path.join(directory + 'Segment',filename),\n",
        "                                       target_size=(img_width, img_height))) # Читаем очередную картинку и добавляем ее в список изображения с указанным target_size                                                      \n",
        "print ('Обучающая выборка загржуена. Время загрузки: ', time.time() - cur_time, 'c', sep='') # Отображаем время загрузки картинок обучающей выборки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRG5IXMpgRry"
      },
      "source": [
        "n = 5 # Количество выводимых случайных картинок\n",
        "fig, axs = plt.subplots(1, n, figsize=(25, 5)) #Создаем полотно из n графиков\n",
        "for i in range(n): # Выводим в цикле n случайных изображений\n",
        "  img = random.choice(segments_airplane) # Выбираем случайное фото для отображения\n",
        "  axs[i].imshow(img) # Отображаем фото\n",
        "plt.show() #Показываем изображения"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxk5YLHMgXl_"
      },
      "source": [
        "## Создание выборки\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=6556"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qkSZ7VmgY9D"
      },
      "source": [
        "# Функция преобразования пикселя сегментированного изображения в индекс (6 классов)\n",
        "def color2index(color):\n",
        "    index=0\n",
        "    if (color[0] + color[1] + color[2]) > 20  : index = 1 # самолет    \n",
        "    return index  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXs3W5I4gaon"
      },
      "source": [
        "def index2color(index2):\n",
        "    index = np.argmax(index2)\n",
        "    color=[]\n",
        "    if index == 0:\n",
        "        color = [0, 0, 0]  # фон\n",
        "    elif index == 1:\n",
        "        color = [255, 0, 0]  # самолет\n",
        "    return color "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luxXYLxogcRU"
      },
      "source": [
        "# Функция перевода индекса пикслея в to_categorical\n",
        "def rgbToohe(y, num_classes): \n",
        "  y2 = y.copy() # Создаем копию входного массива\n",
        "  y = y.reshape(y.shape[0] * y.shape[1], 3) # Решейпим в двумерный массив\n",
        "  yt = [] # Создаем пустой лист\n",
        "  for i in range(len(y)): # Проходим по всем трем канала изображения\n",
        "    yt.append(utils.to_categorical(color2index(y[i]), num_classes=num_classes)) # Переводим пиксели в индексы и преобразуем в OHE\n",
        "  yt = np.array(yt) # Преобразуем в numpy\n",
        "  yt = yt.reshape(y2.shape[0], y2.shape[1], num_classes) # Решейпим к исходныму размеру\n",
        "  return yt # Возвращаем сформированный массив"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuiZREgkgh6J"
      },
      "source": [
        "# Функция формирования yTrain\n",
        "def yt_prep(data, num_classes):\n",
        "  yTrain = [] # Создаем пустой список под карты сегметации\n",
        "  for seg in data: # Пробегаем по всем файлам набора с сегминтированными изображениями\n",
        "    y = image.img_to_array(seg) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "    y = rgbToohe(y, num_classes) # Получаем OHE-представление сформированного массива\n",
        "    yTrain.append(y) # Добавляем очередной элемент в yTrain\n",
        "    if len(yTrain) % 100 == 0: # Каждые 100 шагов\n",
        "      print(len(yTrain)) # Выводим количество обработанных изображений\n",
        "  return np.array(yTrain) # Возвращаем сформированный yTrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBVZe0W1gkig"
      },
      "source": [
        "xTrain = [] # Создаем пустой список под обучающую выборку\n",
        "for img in images_airplane: \n",
        "    x = image.img_to_array(img) # Переводим изображение в numpy-массив размерностью: высота - ширина - количество каналов\n",
        "    xTrain.append(x) # Добавляем очередной элемент в xTrain\n",
        "xTrain = np.array(xTrain) # Переводим в numpy\n",
        "print(xTrain.shape) # Размерность обучающей выборки"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwGL0UhlglF9"
      },
      "source": [
        "cur_time = time.time()\n",
        "yTrain = yt_prep(segments_airplane, num_classes) \n",
        "print('Время обработки: ', round(time.time() - cur_time, 2),'c')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ufNBXJ6gwHh"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(xTrain, yTrain, test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVf-ZmRugynC"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qld2ZK-hg4c6"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69o-S6oZg6E7"
      },
      "source": [
        "'''\n",
        "  Функция создания сети\n",
        "    Входные параметры:\n",
        "    - num_classes - количество классов\n",
        "    - input_shape - размерность карты сегментации\n",
        "'''\n",
        "def unet(num_classes = 3, input_shape= (88, 120, 3)):\n",
        "    img_input = Input(input_shape)                                         # Создаем входной слой с размерностью input_shape\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input) # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)         # Добавляем Conv2D-слой с 64-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_1_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_1_out\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)        # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)        # Добавляем Conv2D-слой с 128-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_2_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_2_out\n",
        "\n",
        "    x = MaxPooling2D()(block_2_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_3_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_3_out\n",
        "\n",
        "    x = MaxPooling2D()(block_3_out)                                        # Добавляем слой MaxPooling2D\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)        # Добавляем Conv2D-слой с 512-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)        # Добавляем Conv2D-слой с 256-нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    block_4_out = Activation('relu')(x)                                    # Добавляем слой Activation и запоминаем в переменной block_4_out\n",
        "    x = block_4_out \n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_3_out])                                      # Объединем текущий слой со слоем block_3_out\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 256 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    # UP 3\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)    # Добавляем слой Conv2DTranspose с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_2_out])                                      # Объединем текущий слой со слоем block_2_out\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)                             # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x)                                            # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x)                                              # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 128 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # Добавляем слой Conv2DTranspose с 64 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = concatenate([x, block_1_out])  # Объединем текущий слой со слоем block_1_out\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x) # Добавляем слой Conv2D с 64 нейронами\n",
        "    x = BatchNormalization()(x) # Добавляем слой BatchNormalization\n",
        "    x = Activation('relu')(x) # Добавляем слой Activation\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)  # Добавляем Conv2D-Слой с softmax-активацией на num_classes-нейронов\n",
        "\n",
        "    model = Model(img_input, x) # Создаем модель с входом 'img_input' и выходом 'x'\n",
        "\n",
        "    # Компилируем модель \n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    \n",
        "    return model # Возвращаем сформированную модель"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db49uTk0g6xj"
      },
      "source": [
        "history = modelAir.fit(x_train, y_train, epochs=35, batch_size=16, validation_data = (x_val, y_val)) # Обучаем модель на выборке по трем классам"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8yZ3VPj2GgP"
      },
      "source": [
        "modelAir.save_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelAir.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN20gYTeg8lG"
      },
      "source": [
        "## Распознавание\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/TUx-Fe9BQoU?t=6637"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF1SWpsa2NGf"
      },
      "source": [
        "modelAir = unet(2, (img_width, img_height,3))\n",
        "modelAir.load_weights('/content/drive/My Drive/Занятия/Февральский курс/Занятие 14/modelAir.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_lI88MEg-X-"
      },
      "source": [
        "count = 5\n",
        "n_classes = 2\n",
        "indexes = np.random.randint(0, len(x_val), count) # Получаем count случайных индексов\n",
        "fig, axs = plt.subplots(2, count, figsize=(25, 5)) #Создаем полотно из n графиков\n",
        "for i,idx in enumerate(indexes): # Проходим по всем сгенерированным индексам\n",
        "  predict = np.array(modelAir.predict(x_val[idx].reshape(1, img_width, img_height, 3))) # Предиктим картику\n",
        "  pr = predict[0] # Берем нулевой элемент из перидкта\n",
        "  pr1 = [] # Пустой лист под сегментированную картинку из predicta\n",
        "  pr = pr.reshape(-1, n_classes) # Решейпим предикт\n",
        "  for k in range(len(pr)): # Проходим по всем уровням (количесвто классов)\n",
        "    pr1.append(index2color(pr[k])) # Переводим индекс в писксель\n",
        "  pr1 = np.array(pr1) # Преобразуем в numpy\n",
        "  pr1 = pr1.reshape(img_width, img_height,3) # Решейпим к размеру изображения\n",
        "  img = Image.fromarray(pr1.astype('uint8')) # Получаем картику из предикта\n",
        "  axs[0,i].imshow(img.convert('RGBA')) # Отображаем на графике в первой линии\n",
        "  axs[1,i].imshow(Image.fromarray(x_val[idx].astype('uint8'))) # Отображаем на графике в третьей линии оригинальное изображение        \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXMJXHYKhBGk"
      },
      "source": [
        "### Наложение маски"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQvbUxZUhC0i"
      },
      "source": [
        "seg = Image.fromarray(pr1.astype('uint8')).convert('RGBA')\n",
        "plt.imshow(seg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbt6sgGtIUnX"
      },
      "source": [
        "plt.imshow(Image.fromarray(x_val[idx].astype('uint8')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBA3Z_T8IV7Q"
      },
      "source": [
        "mask = np.array(seg)\n",
        "mask[mask[:,:,0] <= 10] = [0, 0, 0, 0]\n",
        "mask[mask[:,:,0] > 10] = [0, 150, 0, 150]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTRdWOqPIYju"
      },
      "source": [
        "img2 = Image.fromarray(x_val[idx].astype('uint8'))\n",
        "img = Image.fromarray(mask).convert('RGBA')\n",
        "img2.paste(img, (0, 0),img)\n",
        "plt.imshow(img2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0wu6prpMyTm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}