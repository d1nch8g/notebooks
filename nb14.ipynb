{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QDkaBE5t0O2"
      },
      "source": [
        "*Теоретический материал:* https://youtu.be/NKh4gS7069g?t=106"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-tBeFP38Rp"
      },
      "source": [
        "# **Import библиотек**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/NKh4gS7069g?t=3856"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j1Wpkvc3Q2s"
      },
      "source": [
        "from google.colab import files # модуль для загрузки файлов в colab\n",
        "import numpy as np #библиотека для работы с массивами данных\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model # из кераса подгружаем абстрактный класс базовой модели, метод загрузки предобученной модели\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input # из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta # из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # загружаем метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # загружаем токенизатор кераса для обработки текста\n",
        "from tensorflow.keras import utils # загружаем утилиты кераса для one hot кодировки\n",
        "from tensorflow.keras.utils import plot_model # удобный график для визуализации архитектуры модели\n",
        "\n",
        "import yaml # импортируем модуль для удобной работы с файлами"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200dSPOYZE7N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf473249-41fb-4307-f06c-44f1500a5c98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxdi0Fqeg1LH"
      },
      "source": [
        "# **Парсинг данных**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/NKh4gS7069g?t=4000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEA8TR_oerov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e3a93a74-9cfc-4828-9e77-556b11905021"
      },
      "source": [
        "######################\n",
        "# Открываем файл с диалогами\n",
        "######################\n",
        "corpus = open('/content/drive/My Drive/Базы/Диалоги(рассказы).yml', 'r') # открываем файл с диалогами в режиме чтения\n",
        "document = yaml.safe_load(corpus) # загружаем файл *глоссарий\n",
        "conversations = document['разговоры'] # загружаем диалоги из файла и заносим в conversations \n",
        "print('Количество пар вопрос-ответ : {}'.format(len(conversations)))\n",
        "print('Пример диалога : {}'.format(conversations[123]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество пар вопрос-ответ : 11905\n",
            "Пример диалога : ['Перезалил?', 'Да вроде бы нет...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg8z8Vj76bu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5e071a5-ead7-47e8-d902-c606f01abd0c"
      },
      "source": [
        "######################\n",
        "# Разбираем вопросы-ответы с проставлением тегов ответам\n",
        "######################\n",
        "# Собираем вопросы и ответы в списки\n",
        "questions = list() # здесь будет список вопросов\n",
        "answers = list() # здесь будет список ответов\n",
        "\n",
        "# В каждом диалоге берем фразу и добавляем в лист\n",
        "# Если в ответе не одна фраза - то сцепляем сколько есть\n",
        "for con in conversations: # для каждой пары вопрос-ответ\n",
        "  if len(con) > 2 : # если ответ содержит более двух предложений (кол-во реплик, кол-во вариантов ответа)\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    replies = con[1:] # а ответную составляем из последующих строк\n",
        "    ans = '' # здесь соберем ответ\n",
        "    for rep in replies: # каждую реплику в ответной реплике\n",
        "      ans += ' ' + rep \n",
        "    answers.append(ans) #добавим в список ответов\n",
        "  elif len(con)> 1: # если на 1 вопрос приходится 1 ответ\n",
        "    questions.append(con[0]) # то вопросительную реплику отправляем в список вопросов\n",
        "    answers.append(con[1]) # а ответную в список ответов\n",
        "\n",
        "# Очищаем строки с неопределенным типов ответов\n",
        "answersCleaned = list()\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answersCleaned.append(answers[i]) #если тип - строка, то добавляем в ответы\n",
        "  else:\n",
        "    questions.pop(i) # если не строка, то ответ не добавился, и плюс убираем соответствующий вопрос\n",
        "\n",
        "# Сделаем теги-метки для начала и конца ответов\n",
        "answers = list()\n",
        "for i in range(len(answersCleaned)):\n",
        "  answers.append( '<START> ' + answersCleaned[i] + ' <END>' )\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[200]))\n",
        "print('Ответ : {}'.format(answers[200]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Вопрос : Около сотни...\n",
            "Ответ : <START> Точнее! <END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvn1jvRd9tep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d51889a3-77de-40cd-8676-79f13f7f5cb4"
      },
      "source": [
        "######################\n",
        "# Подключаем керасовский токенизатор и собираем словарь индексов\n",
        "######################\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers) # загружаем в токенизатор список вопросов-ответов для сборки словаря частотности\n",
        "vocabularyItems = list(tokenizer.word_index.items()) # список с cодержимым словаря\n",
        "vocabularySize = len(vocabularyItems)+1 # размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))\n",
        "print( 'Размер словаря : {}'.format(vocabularySize))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('я', 5), ('а', 6), ('ты', 7), ('это', 8), ('да', 9), ('в', 10), ('нет', 11), ('как', 12), ('и', 13), ('вы', 14), ('ну', 15), ('с', 16), ('на', 17), ('же', 18), ('так', 19), ('он', 20), ('у', 21), ('кто', 22), ('где', 23), ('все', 24), ('мы', 25), ('то', 26), ('мне', 27), ('тебя', 28), ('меня', 29), ('здесь', 30), ('еще', 31), ('почему', 32), ('о', 33), ('там', 34), ('тебе', 35), ('есть', 36), ('его', 37), ('за', 38), ('куда', 39), ('вот', 40), ('ничего', 41), ('вас', 42), ('знаю', 43), ('чем', 44), ('но', 45), ('она', 46), ('они', 47), ('ли', 48), ('чего', 49), ('вам', 50)]\n",
            "Размер словаря : 15104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsUqzEBXg9Mu"
      },
      "source": [
        "# **Подготовка выборки**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/NKh4gS7069g?t=4390"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4nNBJUQgebF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5e6697d7-23a6-4b06-bebc-7e8962e23de7"
      },
      "source": [
        "######################\n",
        "# Устанавливаем закодированные входные данные(вопросы)\n",
        "######################\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions) # разбиваем текст вопросов на последовательности индексов\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions]) # уточняем длину самого большого вопроса\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие вопросы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "encoderForInput = np.array(paddedQuestions) # переводим в numpy массив\n",
        "print('Пример оригинального вопроса на вход : {}'.format(questions[100])) \n",
        "print('Пример кодированного вопроса на вход : {}'.format(encoderForInput[100])) \n",
        "print('Размеры закодированного массива вопросов на вход : {}'.format(encoderForInput.shape)) \n",
        "print('Установленная длина вопросов на вход : {}'.format(maxLenQuestions)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального вопроса на вход : Какая же мораль?\n",
            "Пример кодированного вопроса на вход : [ 170   18 5709    0    0    0    0    0    0    0    0]\n",
            "Размеры закодированного массива вопросов на вход : (11900, 11)\n",
            "Установленная длина вопросов на вход : 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tjvhMuzqFJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7fd84598-5371-48de-9fb5-a5719f111f44"
      },
      "source": [
        "######################\n",
        "# Устанавливаем раскодированные входные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers]) # уточняем длину самого большого ответа\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть\n",
        "decoderForInput = np.array(paddedAnswers) # переводим в numpy массив\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100])) \n",
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:30])) \n",
        "print('Размеры раскодированного массива ответов на вход : {}'.format(decoderForInput.shape)) \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример оригинального ответа на вход: <START> Никакой. Так просто вспомнилось. <END>\n",
            "Пример раскодированного ответа на вход : [    1   673    19    93 10558     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Размеры раскодированного массива ответов на вход : (11900, 13)\n",
            "Установленная длина ответов на вход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwsKk9dzNeqI"
      },
      "source": [
        "######################\n",
        "# Раскодированные выходные данные(ответы)\n",
        "######################\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) # разбиваем текст ответов на последовательности индексов\n",
        "for i in range(len(tokenizedAnswers)) : # для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:] # избавляемся от тега <START>\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "oneHotAnswers = utils.to_categorical(paddedAnswers, vocabularySize) # переводим в one hot vector\n",
        "decoderForOutput = np.array(oneHotAnswers) # и сохраняем в виде массива numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRl1k7SVaA6w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3e44f794-6741-4c28-ea69-55693cc0e3b0"
      },
      "source": [
        "print('Пример раскодированного ответа на вход : {}'.format(decoderForInput[100][:21]))  \n",
        "print('Пример раскодированного ответа на выход : {}'.format(decoderForOutput[100][4][:21])) \n",
        "print('Размеры раскодированного массива ответов на выход : {}'.format(decoderForOutput.shape))\n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Пример раскодированного ответа на вход : [    1   673    19    93 10558     2     0     0     0     0     0     0\n",
            "     0]\n",
            "Пример раскодированного ответа на выход : [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Размеры раскодированного массива ответов на выход : (11900, 13, 15104)\n",
            "Установленная длина вопросов на выход : 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KR6Mh_hp1f"
      },
      "source": [
        "# **Параметры нейросети и модель обучения**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/NKh4gS7069g?t=4982"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRKDr4rhXcZ"
      },
      "source": [
        "######################\n",
        "# Первый входной слой, кодер, выходной слой\n",
        "######################\n",
        "encoderInputs = Input(shape=(None , )) # размеры на входе сетки (здесь будет encoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True) (encoderInputs)\n",
        "# Затем выход с Embedding пойдёт в LSTM слой, на выходе у которого будет два вектора состояния - state_h , state_c\n",
        "# Вектора состояния - state_h , state_c зададутся в LSTM слое декодера в блоке ниже\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)\n",
        "encoderStates = [state_h, state_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_yv8Y6QWX2D"
      },
      "source": [
        "######################\n",
        "# Второй входной слой, декодер, выходной слой\n",
        "######################\n",
        "decoderInputs = Input(shape=(None, )) # размеры на входе сетки (здесь будет decoderForInput)\n",
        "# Эти данные проходят через слой Embedding (длина словаря, размерность) \n",
        "# mask_zero=True - игнорировать нулевые padding при передаче в LSTM. Предотвратит вывод ответа типа: \"У меня все хорошо PAD PAD PAD PAD PAD PAD..\"\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs) \n",
        "# Затем выход с Embedding пойдёт в LSTM слой, которому передаются вектора состояния - state_h , state_c\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates)\n",
        "# И от LSTM'а сигнал decoderOutputs пропускаем через полносвязный слой с софтмаксом на выходе\n",
        "decoderDense = Dense(vocabularySize, activation='softmax') \n",
        "output = decoderDense (decoderOutputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYnTen_UWc5F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "82aebcb2-fa9f-4517-db7c-e3ecf83e092e"
      },
      "source": [
        "######################\n",
        "# Собираем тренировочную модель нейросети\n",
        "######################\n",
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "print(model.summary()) # выведем на экран информацию о построенной модели нейросети\n",
        "plot_model(model, to_file='model.png') # и построим график для визуализации слоев и связей между ними"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 200)    3020800     input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, None, 200)    3020800     input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, 200), (None, 320800      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, None, 200),  320800      embedding_6[0][0]                \n",
            "                                                                 lstm_5[0][1]                     \n",
            "                                                                 lstm_5[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 15104)  3035904     lstm_6[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,719,104\n",
            "Trainable params: 9,719,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbelEm0zhadD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e983eeb4-e8e5-42d4-ef4c-f5ecf79b4e97"
      },
      "source": [
        "# Запустим обучение и сохраним модель\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=50, epochs=30) \n",
        "model.save( '/content/drive/My Drive/Предобученные сети/model_30epochs(rms).h5' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 2.2128\n",
            "Epoch 2/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.9750\n",
            "Epoch 3/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.9264\n",
            "Epoch 4/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8892\n",
            "Epoch 5/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8566\n",
            "Epoch 6/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.8236\n",
            "Epoch 7/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.7924\n",
            "Epoch 8/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.7603\n",
            "Epoch 9/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.7260\n",
            "Epoch 10/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.6926\n",
            "Epoch 11/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.6593\n",
            "Epoch 12/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.6251\n",
            "Epoch 13/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.5906\n",
            "Epoch 14/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.5560\n",
            "Epoch 15/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.5235\n",
            "Epoch 16/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.4912\n",
            "Epoch 17/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.4601\n",
            "Epoch 18/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.4295\n",
            "Epoch 19/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.3988\n",
            "Epoch 20/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.3687\n",
            "Epoch 21/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.3374\n",
            "Epoch 22/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.3069\n",
            "Epoch 23/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2784\n",
            "Epoch 24/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2508\n",
            "Epoch 25/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2261\n",
            "Epoch 26/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.2027\n",
            "Epoch 27/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.1808\n",
            "Epoch 28/30\n",
            "238/238 [==============================] - 10s 41ms/step - loss: 1.1593\n",
            "Epoch 29/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.1353\n",
            "Epoch 30/30\n",
            "238/238 [==============================] - 10s 42ms/step - loss: 1.1132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_U_rY8UiRL2"
      },
      "source": [
        "# **Подготовка и запуск рабочей нейросети с генерацией ответов**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/NKh4gS7069g?t=6024"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9utvcjh2co"
      },
      "source": [
        "######################\n",
        "# Создаем рабочую модель для вывода ответов на запросы пользователя\n",
        "######################\n",
        "def makeInferenceModels():\n",
        "  # Определим модель кодера, на входе далее будут закодированные вопросы(encoderForInputs), на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # и ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSSOhZpgh9LI"
      },
      "source": [
        "######################\n",
        "# Создадим функцию, которая преобразует вопрос пользователя в последовательность индексов\n",
        "######################\n",
        "def strToTokens(sentence: str): # функция принимает строку на вход (предложение с вопросом)\n",
        "  words = sentence.lower().split() # приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list() # здесь будет последовательность токенов/индексов\n",
        "  for word in words: # для каждого слова в предложении\n",
        "    tokensList.append(tokenizer.word_index[word]) # определяем токенизатором индекс и добавляем в список\n",
        "\n",
        "    # Функция вернёт вопрос в виде последовательности индексов, ограниченной длиной самого длинного вопроса из нашей базы вопросов\n",
        "  return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ0Dxd1eiEid"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем модель\n",
        "######################\n",
        "\n",
        "encModel , decModel = makeInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation[:-3]) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfhu067toXGQ"
      },
      "source": [
        "# **Загрузка и запуск предобученной модели**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/NKh4gS7069g?t=7271"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ngvBy5yrY3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b4a02d5-1a29-4bcd-f6d3-582b2e4b4c09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Lg3eOVqKyP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "609bd676-347d-4bc2-8f71-2632e1bb78fa"
      },
      "source": [
        "# Подгружаем модель из файла и выведем её параметры\n",
        "model = load_model('/content/gdrive/My Drive/Предобученные сети/model_chatbot_100epochs(rms)+50(ada).h5')\n",
        "#model = load_model('model_chatbot_100epochs(rms)+50(ada) (1).h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 200)    3020800     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 200)    3020800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 200), (None, 320800      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 200),  320800      embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 15104)  3035904     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 9,719,104\n",
            "Trainable params: 9,719,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEfb58cXqsKi"
      },
      "source": [
        "######################\n",
        "# Устанавливаем связи между слоями рабочей модели и предобученной\n",
        "######################\n",
        "def loadInferenceModels():\n",
        "  encoderInputs = model.input[0]   # входом энкодера рабочей модели будет первый инпут предобученной модели(input_1)\n",
        "  encoderEmbedding = model.layers[2] # связываем эмбединг слои(model.layers[2] это embedding_1)\n",
        "  encoderOutputs, state_h_enc, state_c_enc = model.layers[4].output # вытягиваем аутпуты из первого LSTM слоя обуч.модели и даем энкодеру(lstm_1)\n",
        "  encoderStates = [state_h_enc, state_c_enc] # ложим забранные состояния в состояния энкодера\n",
        "  encoderModel = Model(encoderInputs, encoderStates) # формируем модель\n",
        "\n",
        "  decoderInputs = model.input[1]   # входом декодера рабочей модели будет второй инпут предобученной модели(input_2)\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # обозначим размерность для входного слоя с состоянием state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # возьмем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderEmbedding = model.layers[3] # связываем эмбединг слои(model.layers[3] это embedding_2)\n",
        "  decoderLSTM = model.layers[5] # связываем LSTM слои(model.layers[5] это lstm_2)\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding.output, initial_state=decoderStatesInputs)\n",
        "  decoderStates = [state_h, state_c] # LSTM даст нам новые состояния\n",
        "\n",
        "  decoderDense = model.layers[6] # связываем полносвязные слои(model.layers[6] это dense_1)\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # выход с LSTM мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "    # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "    # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "  return encoderModel , decoderModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpsqjakx2rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6485bd0e-ef95-43d8-cb7b-cec8fa2efa4c"
      },
      "source": [
        "######################\n",
        "# Устанавливаем окончательные настройки и запускаем рабочую модель над предобученной\n",
        "######################\n",
        "\n",
        "encModel , decModel = loadInferenceModels() # запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "for _ in range(6): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  statesValues = encModel.predict(strToTokens(input( 'Задайте вопрос : ' )))\n",
        "  # Создаём пустой массив размером (1, 1)\n",
        "  emptyTargetSeq = np.zeros((1, 1))    \n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "\n",
        "  stopCondition = False # зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = '' # здесь будет собираться генерируемый ответ\n",
        "  while not stopCondition : # пока не сработало стоп-условие\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    #argmax пробежит по вектору decOutputs'а[0,0,15104], найдет макс.значение, и вернёт нам номер индекса под которым оно лежит в массиве\n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # argmax возьмем от оси, в которой 15104 элементов. Получили индекс предсказанного слова.\n",
        "    sampledWord = None # создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index: # если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word # выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # то срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1)) # создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c] # и состояния, обновленные декодером\n",
        "    # и продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(decodedTranslation) # выводим ответ сгенерированный декодером"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Задайте вопрос : как дела\n",
            " за ночь сделали пятнадцать комплектов end\n",
            "Задайте вопрос : как дела\n",
            " за ночь сделали пятнадцать комплектов end\n",
            "Задайте вопрос : выход\n",
            " мы не стали будить тебя раньше end\n",
            "Задайте вопрос : добрый день\n",
            " как это вас не задело end\n",
            "Задайте вопрос : пока\n",
            " а это бы правда end\n",
            "Задайте вопрос : ты кто\n",
            " наш вид известен как люди end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98O0XcM9yCbm"
      },
      "source": [
        "# **Глоссарий**\n",
        "-  Seq2Seq - sequence-to-sequence модель, состоит из двух рекуррентных нейронных сетей (RNN): \n",
        "\n",
        "encoder (кодер), которая обрабатывает входные данные,\n",
        "\n",
        "decoder (декодер), которая генерирует данные вывода.\n",
        "- Yaml - удобный текстовый формат, позволяющий хранить структурированные данные в иерархии. https://ru.bmstu.wiki/YAML\n",
        "yaml.safe_load - безопасный метод загрузки данных из файлов, предотвращающий возможность запуска произвольного кода для файлов из ненадежных источников\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}